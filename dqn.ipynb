{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94cf0a7f-2d1c-453d-99a6-4d1fbd415973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e93345a-1e2d-45c8-bc8b-10a6f2b184a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import wandb\n",
    "\n",
    "%aimport util.decaying\n",
    "%aimport dqnmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9468f036-0d54-4303-9e1a-55f92999006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEM_SIZE = 8000\n",
    "MIN_MEM_SIZE = 1000\n",
    "\n",
    "DISCOUNT_START = 0.8\n",
    "DISCOUNT_END = 0.94\n",
    "DISCOUNT_DURATION = 4000\n",
    "\n",
    "EPSILON_START = 0.5\n",
    "EPSILON_END = 0.03\n",
    "EPSILON_DURATION = 4000\n",
    "\n",
    "SIMULATE_EVERY = 4\n",
    "USE_PRO_PLAY_CHANCE = 0.2\n",
    "\n",
    "EPISODES = 50\n",
    "BATCH_SIZE = 164\n",
    "LEARNING_RATE = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24011d4e-ca65-42f8-8079-5de37bbb4e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "          \n",
      "█████     \n",
      "████      \n",
      "████ █████\n",
      "████  ████\n",
      "████ █████\n",
      "██████████\n"
     ]
    }
   ],
   "source": [
    "%run tetris-environment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4ee64b-a680-4610-aa11-4d22082ce021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device\n",
    "device = 'cuda'\n",
    "\n",
    "use_pro_replays = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14b38626-0551-4689-866f-3b777384bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dqnmodel.DQNModel(50)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd8766de-e03e-4c04-be72-b560c34d89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = util.decaying.DecayingDiscount(EPSILON_START, EPSILON_END, EPSILON_DURATION)\n",
    "discount = util.decaying.DecayingLinear(DISCOUNT_START, DISCOUNT_END, DISCOUNT_DURATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f70331-d5ba-4924-ae12-4a0c989f638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_state(states, use_epsilon=True):\n",
    "    if not use_epsilon or random.random() > epsilon.get():\n",
    "        # use the q-network (not the target network) for chosing the next state\n",
    "        q_values = model.model(states)\n",
    "        return torch.argmax(q_values)\n",
    "    else:\n",
    "        return random.choice(range(len(states)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a97a3758-3b69-46ee-b570-14d115f925f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TetrisEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5c250e-694d-4bfd-9896-ea3865931f30",
   "metadata": {},
   "source": [
    "### Fill the replay buffer by playing games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e8aac1f-362b-4c46-8134-5c946e027b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b98a9bddbc4804930621ba5e38ac9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [17, 200]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     states, scores, clears, dones \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_next_states()\n\u001b[0;32m---> 15\u001b[0m     chosen_index \u001b[38;5;241m=\u001b[39m \u001b[43mget_best_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     replay_buffer\u001b[38;5;241m.\u001b[39mappend((env\u001b[38;5;241m.\u001b[39mget_current_state(), states[chosen_index], scores[chosen_index], dones[chosen_index]))\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dones[chosen_index]:\n",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m, in \u001b[0;36mget_best_state\u001b[0;34m(states, use_epsilon)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_state\u001b[39m(states, use_epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_epsilon \u001b[38;5;129;01mor\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m>\u001b[39m epsilon\u001b[38;5;241m.\u001b[39mget():\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;66;03m# use the q-network (not the target network) for chosing the next state\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m         q_values \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39margmax(q_values)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [17, 200]"
     ]
    }
   ],
   "source": [
    "replay_buffer = []\n",
    "\n",
    "def to_torch(state):\n",
    "    return torch.from_numpy(states.reshape(states.shape[0], -1)).float()\n",
    "\n",
    "with tqdm(total=MIN_MEM_SIZE/20) as pbar:\n",
    "    while len(replay_buffer) < MIN_MEM_SIZE:\n",
    "        env.reset()\n",
    "        pbar.update(1)\n",
    "\n",
    "        # play moves until game over\n",
    "        while True:\n",
    "            states, scores, clears, dones = env.get_next_states()\n",
    "\n",
    "            chosen_index = get_best_state(torch.from_numpy(states.reshape(-1, 200)).float().to(device))\n",
    "\n",
    "            replay_buffer.append((env.get_current_state(), states[chosen_index], scores[chosen_index], dones[chosen_index]))\n",
    "\n",
    "            if dones[chosen_index]:\n",
    "                break\n",
    "            else:\n",
    "                env.step(states[chosen_index], clears[chosen_index], scores[chosen_index])\n",
    "\n",
    "# states, _, _, _, = env.get_next_states()\n",
    "# states = torch.from_numpy(states.reshape(states.shape[0], -1)).float()\n",
    "\n",
    "# model(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d022535-9ad3-4831-bb19-66735b324dde",
   "metadata": {},
   "source": [
    "### Fill the replay buffer from professional player moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f122d02d-9d11-49e8-a67e-97b77edf3e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3ca62401874400aa679ccfa1cf945d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ProReplayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, train):\n",
    "        self.path = path\n",
    "        self.file_list = glob.glob(f'{path}\\\\*.json')\n",
    "        self.train = train\n",
    "        \n",
    "        def string_to_board(string):\n",
    "            return torch.tensor([int(c) for c in list(string)])\n",
    "        \n",
    "        # to speed things up, load the whole dataset to memory\n",
    "        self.buffer = []\n",
    "        for idx, file in tqdm(enumerate(self.file_list)):\n",
    "            df = pd.read_csv(file)\n",
    "\n",
    "            for index, row in df.iterrows():\n",
    "                self.buffer.append((\n",
    "                    string_to_board(row.current).reshape((20, 10)).to(device),\n",
    "                    string_to_board(row.next).reshape((20, 10)).to(device),\n",
    "                    row.score,\n",
    "                    row.done\n",
    "                ))\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.buffer[idx]\n",
    "\n",
    "\n",
    "replay_buffer_dataset = ProReplayDataset('I:\\\\AI\\\\processed-dqn', True)\n",
    "replay_buffer_loader = torch.utils.data.DataLoader(dataset=replay_buffer_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c2fa0-925c-49d9-8986-ffaf8b341fef",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa651a19-cb69-427d-acbc-77b2f344eec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfischly\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Binaries\\WPy64-31050\\notebooks\\tetris-ai\\wandb\\run-20230105_212930-fp3k4ack</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fischly/tetris-dqn/runs/fp3k4ack\" target=\"_blank\">avid-river-12</a></strong> to <a href=\"https://wandb.ai/fischly/tetris-dqn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/fischly/tetris-dqn/runs/fp3k4ack?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1e779ed15a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='tetris-dqn', config={\n",
    "    'learning-rate': LEARNING_RATE,\n",
    "    'batch-size': BATCH_SIZE,\n",
    "    \n",
    "    'replay-max-size': MEM_SIZE,\n",
    "    'replay-min-size': MIN_MEM_SIZE,\n",
    "    \n",
    "    'epsilon-start': EPSILON_START,\n",
    "    'epsilon-end': EPSILON_END,\n",
    "    'epsilon-duration': EPSILON_DURATION,\n",
    "    \n",
    "    'discount-start': DISCOUNT_START,\n",
    "    'discount-end': DISCOUNT_END,\n",
    "    'discount-duration': DISCOUNT_DURATION,\n",
    "    \n",
    "    'pro-play-chance': USE_PRO_PLAY_CHANCE,\n",
    "    'simulate-every': SIMULATE_EVERY,\n",
    "\n",
    "    # 'resume': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c95226ce-c7bb-4def-a805-11748c9b7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext line_profiler\n",
    "# %prun train(replay_buffer)\n",
    "\n",
    "epsilon = util.decaying.DecayingDiscount(EPSILON_START, EPSILON_END, EPSILON_DURATION)\n",
    "discount = util.decaying.DecayingLinear(DISCOUNT_START, DISCOUNT_END, DISCOUNT_DURATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "de9b5f4d-158f-4d4f-b4a4-37244fb840b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if use_pro_replays:\n",
    "# replay_buffer = []\n",
    "# replay_buffer_iter = iter(replay_buffer_loader)\n",
    "# discount.current = 0.965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "538048ff-be42-42dd-9bac-5b209ab8853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18dcbae3936244c8b20ff8fc460ebf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def train():\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = torch.optim.AdamW(model.model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "training_loss = []\n",
    "training_scores = []\n",
    "\n",
    "for episode in tqdm(range(2000)): # tqdm(range(EPISODES)):\n",
    "    use_pro_replays = random.random() < USE_PRO_PLAY_CHANCE\n",
    "    \n",
    "    # play another game\n",
    "    if episode % SIMULATE_EVERY == 1:\n",
    "        env.reset()\n",
    "        while True:\n",
    "            states, scores, clears, dones = env.get_next_states()\n",
    "\n",
    "            chosen_index = get_best_state(torch.from_numpy(states.reshape(-1, 200)).float().to(device))\n",
    "\n",
    "            replay_buffer.append((env.get_current_state(), states[chosen_index], scores[chosen_index], dones[chosen_index]))\n",
    "\n",
    "            if dones[chosen_index]:\n",
    "                training_scores.append({'epoch': episode, 'score': env.score})\n",
    "                break\n",
    "            else:\n",
    "                env.step(states[chosen_index], clears[chosen_index], scores[chosen_index])\n",
    "\n",
    "        if len(replay_buffer) > MEM_SIZE:\n",
    "            replay_buffer = replay_buffer[int(MEM_SIZE/10):]\n",
    "            \n",
    "        wandb.log({'game/score': env.score,\n",
    "                   'game/singles': env.clears[0], 'game/doubles': env.clears[1], 'game/triples': env.clears[2], 'game/quads': env.clears[3],\n",
    "                   'game/tspins': env.tspins, 'game/all_clears': env.all_clears, 'game/moves': env.moves })\n",
    "\n",
    "\n",
    "    # get the batch, consisting of (current_state, next_state, score, done), and extract current and next states\n",
    "    if use_pro_replays:\n",
    "        batch = next(replay_buffer_iter)\n",
    "        current_states = batch[0].reshape(-1, 200).float()\n",
    "        next_states = batch[0].reshape(-1, 200).float()\n",
    "    else:\n",
    "        # take sample from replay memory\n",
    "        batch = random.sample(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "        current_states = torch.from_numpy(np.array([s[0].reshape(200) for s in batch])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.array([s[1].reshape(200) for s in batch])).float().to(device)\n",
    "\n",
    "    # get the q-values of the current state\n",
    "    y_hat = model.model(current_states)\n",
    "\n",
    "    # calculate expected q-values of the next state using the target-network\n",
    "    next_q_values = model.target_model(next_states)\n",
    "    y = []\n",
    "    if use_pro_replays:\n",
    "        for i in range(batch[3].shape[0]):\n",
    "            done = batch[3][i]\n",
    "            score = batch[2][i].float()\n",
    "            \n",
    "            if not done:\n",
    "                new_q = score + discount.current * next_q_values[i]\n",
    "            else:\n",
    "                new_q = score\n",
    "            \n",
    "            y.append(new_q)\n",
    "    else:\n",
    "        for i, (_, _, score, done) in enumerate(batch):\n",
    "            if not done:\n",
    "                new_q = score + discount.current * next_q_values[i]\n",
    "            else:\n",
    "                new_q = score\n",
    "\n",
    "            y.append(new_q)\n",
    "\n",
    "    \n",
    "            \n",
    "    # fit the model to the expected q value\n",
    "    loss = criterion(y_hat, torch.tensor(y).reshape(BATCH_SIZE if not use_pro_replays else batch[3].shape[0], 1).to(device))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epsilon.step()\n",
    "    discount.step()\n",
    "    \n",
    "    model.step()\n",
    "\n",
    "    wandb.log({'training/loss': loss.item()})\n",
    "    training_loss.append({'epoch': episode, 'loss': loss.item()})\n",
    "        # print(loss)\n",
    "        \n",
    "# sns.lineplot(data=pd.DataFrame(training_loss), x='epoch', y='loss')\n",
    "# sns.lineplot(data=pd.DataFrame(training_scores), x='epoch', y='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e71a12-23a3-4406-b9e9-ff8ae59da7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6b9bea3b-c207-4e90-9ac3-41d242b98a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n",
      "0.030000000000020254\n"
     ]
    }
   ],
   "source": [
    "# sns.lineplot(data=pd.DataFrame(training_scores), x='epoch', y='score')\n",
    "print(discount.current)\n",
    "print(epsilon.current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ebe2b8b5-be56-4dcd-8c2f-4e3d029bca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# env.reset()\n",
    "# print(env.current_piece)\n",
    "\n",
    "# while True:\n",
    "#     states, scores, clears, dones = env.get_next_states()\n",
    "\n",
    "#     chosen_index = get_best_state(torch.from_numpy(states.reshape(-1, 200)).float())\n",
    "\n",
    "#     env._print_state(states[chosen_index])\n",
    "#     print()\n",
    "    \n",
    "#     # replay_buffer.append((env.get_current_state(), states[chosen_index], scores[chosen_index], dones[chosen_index]))\n",
    "\n",
    "#     if dones[chosen_index]:\n",
    "#         print(f'Score: {env.score}')\n",
    "#         print(f'Clears: {env.clears}, t-spins: {env.tspins}, alll_clears: {env.all_clears}')\n",
    "#         break\n",
    "#     else:\n",
    "#         env.step(states[chosen_index], clears[chosen_index], scores[chosen_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0281bfe9-08ac-448c-b01a-cdb12bf5bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 750\n",
      "Clears: [7, 0, 0, 0], t-spins: 0, alll_clears: 0\n",
      "Score: 3350.0\n",
      "Clears: [19, 2, 0, 0], t-spins: 2, alll_clears: 0\n",
      "Score: 700\n",
      "Clears: [5, 1, 0, 0], t-spins: 0, alll_clears: 0\n",
      "Score: 1500\n",
      "Clears: [11, 1, 0, 0], t-spins: 0, alll_clears: 0\n",
      "Score: 1575.0\n",
      "Clears: [10, 0, 0, 0], t-spins: 1, alll_clears: 0\n",
      "Score: 1750\n",
      "Clears: [12, 2, 0, 0], t-spins: 0, alll_clears: 0\n",
      "Score: 700\n",
      "Clears: [7, 0, 0, 0], t-spins: 0, alll_clears: 0\n",
      "Score: 950\n",
      "Clears: [9, 0, 0, 0], t-spins: 0, alll_clears: 0\n",
      "Score: 1750\n",
      "Clears: [10, 2, 1, 0], t-spins: 0, alll_clears: 0\n",
      "Score: 1050\n",
      "Clears: [8, 1, 0, 0], t-spins: 0, alll_clears: 0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "COLORS = {\n",
    "    0: (0,0,0),\n",
    "    1: (255,255,255)\n",
    "    # 0: (128, 0, 128),\n",
    "    # 1: (255, 127, 0),\n",
    "    # 2: (0, 0, 255),\n",
    "    # 3: (255, 255, 0),\n",
    "    # 4: (0, 255, 255),\n",
    "    # 5: (0, 255, 0),\n",
    "    # 6: (255, 0, 0)\n",
    "}\n",
    "\n",
    "def render_gif(states, file_name):\n",
    "    \n",
    "    def gen_image(state):\n",
    "        img = [COLORS[cell] for row in state for cell in row]\n",
    "        img = np.array(img).reshape(20, 10, 3).astype(np.uint8)\n",
    "        img = img[..., ::-1] # Convert RRG to BGR (used by cv2)\n",
    "        img = Image.fromarray(img, 'RGB')\n",
    "\n",
    "        img = img.resize((10 * 25, 20 * 25), Image.Resampling.NEAREST)\n",
    "\n",
    "        return img\n",
    "\n",
    "    frames = []\n",
    "    for state in states:\n",
    "        frames.append(gen_image(state))\n",
    "    \n",
    "    frames[0].save(f'images/{file_name}', format='GIF', append_images=frames, save_all=True, duration=300, loop=0)\n",
    "\n",
    "\n",
    "runs = []\n",
    "def render_run():\n",
    "    \n",
    "    env.reset()\n",
    "    states_to_render = []\n",
    "    \n",
    "    while True:\n",
    "        states, scores, clears, dones = env.get_next_states()\n",
    "\n",
    "        chosen_index = get_best_state(torch.from_numpy(states.reshape(-1, 200)).float(), False)\n",
    "\n",
    "        states_to_render.append(states[chosen_index])\n",
    "\n",
    "        if dones[chosen_index]:\n",
    "            print(f'Score: {env.score}')\n",
    "            print(f'Clears: {env.clears}, t-spins: {env.tspins}, alll_clears: {env.all_clears}')\n",
    "            break\n",
    "        else:\n",
    "            env.step(states[chosen_index], clears[chosen_index], scores[chosen_index])\n",
    "    \n",
    "    runs.append(states_to_render)\n",
    "    \n",
    "for i in range(10):\n",
    "    render_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "28e5c25c-453b-45fa-ae5f-ed9520c5c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_gif(runs[1], 'tetris4.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f6c0fec7-86dd-444d-94db-601795e62697",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/run-13.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3f9875c-754b-41f0-ba92-795f472bdcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.4596, grad_fn=<MinBackward1>)\n",
      "tensor(-0.9907, grad_fn=<MinBackward1>)\n",
      "tensor(-3.4248, grad_fn=<MinBackward1>)\n",
      "tensor(-0.9417, grad_fn=<MinBackward1>)\n",
      "tensor(-4.2111, grad_fn=<MinBackward1>)\n",
      "tensor(-0.3575, grad_fn=<MinBackward1>)\n",
      "tensor(-1.9662, grad_fn=<MinBackward1>)\n",
      "tensor(-0.3889, grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(torch.min(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
